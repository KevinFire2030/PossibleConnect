# Qdrant Distance Metrics 비교 가이드

## 거리 측정 방법이란?

벡터 간의 **유사도** 또는 **거리**를 계산하는 방법입니다. 두 벡터가 얼마나 비슷한지를 측정하는 기준입니다.

## 4가지 거리 측정 방법 비교

### 1. Cosine (코사인 유사도) ✅ **텍스트 임베딩에 권장**

**특징:**
- 벡터 간의 **각도**를 측정
- 벡터의 크기(길이)는 무시하고 방향만 고려
- 0 ~ 1 사이의 값 (1에 가까울수록 유사)

**수식:**
```
Cosine Similarity = (A · B) / (||A|| × ||B||)
```

**장점:**
- ✅ **텍스트 임베딩에 최적**
- ✅ 벡터 크기에 영향받지 않음
- ✅ 정규화된 벡터에서 효과적
- ✅ OpenAI Embeddings와 완벽 호환
- ✅ 의미 기반 검색에 적합

**단점:**
- ❌ 벡터 크기가 중요한 경우 부적합

**적합한 사용 사례:**
- ✅ **텍스트 임베딩** (OpenAI, Cohere 등)
- ✅ **의미 기반 검색**
- ✅ **RAG 시스템**
- ✅ **문서 유사도 검색**
- ✅ **추천 시스템** (사용자 선호도)

**예시:**
```
문서 A: "동아리 소개"
문서 B: "동아리에 대한 설명"
→ Cosine: 높은 유사도 (의미가 비슷함)

문서 A: "동아리 소개"
문서 B: "날씨 정보"
→ Cosine: 낮은 유사도 (의미가 다름)
```

### 2. Euclid (유클리드 거리)

**특징:**
- 벡터 간의 **직선 거리**를 측정
- 고등학교 수학에서 배운 "두 점 사이의 거리"
- 0에 가까울수록 유사

**수식:**
```
Euclidean Distance = √[(x₁-y₁)² + (x₂-y₂)² + ... + (xₙ-yₙ)²]
```

**장점:**
- ✅ 직관적이고 이해하기 쉬움
- ✅ 벡터 크기가 중요한 경우 적합
- ✅ 수치 데이터에 적합

**단점:**
- ❌ 고차원 벡터에서 성능 저하 (차원의 저주)
- ❌ 텍스트 임베딩에는 부적합
- ❌ 벡터 크기에 민감

**적합한 사용 사례:**
- ✅ **이미지 임베딩**
- ✅ **수치 데이터**
- ✅ **좌표 기반 데이터**
- ✅ **저차원 벡터** (2D, 3D)

**예시:**
```
이미지 A: [0.1, 0.2, 0.3, ...]
이미지 B: [0.15, 0.25, 0.35, ...]
→ Euclid: 작은 거리 (비슷한 이미지)
```

### 3. Dot (내적)

**특징:**
- 벡터의 **내적(점곱)** 계산
- 벡터의 크기와 각도를 모두 고려
- 값이 클수록 유사

**수식:**
```
Dot Product = A · B = Σ(Aᵢ × Bᵢ)
```

**장점:**
- ✅ 빠른 계산
- ✅ 정규화된 벡터에서 Cosine과 유사한 결과
- ✅ 특정 모델에 최적화된 경우

**단점:**
- ❌ 벡터 크기에 민감
- ❌ 정규화되지 않은 벡터에서는 부정확할 수 있음

**적합한 사용 사례:**
- ✅ **정규화된 벡터**
- ✅ **특정 임베딩 모델** (모델이 Dot을 권장하는 경우)
- ✅ **빠른 검색이 중요한 경우**

**예시:**
```
정규화된 벡터 A: [0.1, 0.2, 0.3, ...]
정규화된 벡터 B: [0.15, 0.25, 0.35, ...]
→ Dot: 높은 값 (유사함)
```

### 4. Manhattan (맨해튼 거리)

**특징:**
- **L1 거리** 또는 **택시 거리**
- 격자 모양의 도로를 따라 이동하는 거리
- 각 차원의 차이의 절댓값 합

**수식:**
```
Manhattan Distance = |x₁-y₁| + |x₂-y₂| + ... + |xₙ-yₙ|
```

**장점:**
- ✅ 격자형 데이터에 적합
- ✅ 이상치에 덜 민감
- ✅ 특정 분류 문제에 유용

**단점:**
- ❌ 텍스트 임베딩에는 부적합
- ❌ 일반적으로 텍스트 검색에서 사용 빈도 낮음

**적합한 사용 사례:**
- ✅ **격자형 데이터**
- ✅ **이상 탐지**
- ✅ **특정 분류 문제**
- ✅ **저차원 수치 데이터**

**예시:**
```
좌표 A: [1, 2]
좌표 B: [3, 4]
→ Manhattan: |1-3| + |2-4| = 2 + 2 = 4
```

## 비교표

| 특징 | Cosine | Euclid | Dot | Manhattan |
|------|--------|--------|-----|-----------|
| **텍스트 임베딩** | ✅ 최적 | ❌ 부적합 | ⚠️ 조건부 | ❌ 부적합 |
| **이미지 임베딩** | ⚠️ 가능 | ✅ 적합 | ⚠️ 가능 | ⚠️ 가능 |
| **벡터 크기 영향** | ❌ 무시 | ✅ 고려 | ✅ 고려 | ✅ 고려 |
| **고차원 벡터** | ✅ 적합 | ❌ 성능 저하 | ✅ 적합 | ⚠️ 보통 |
| **계산 속도** | ⭐⭐⭐ 빠름 | ⭐⭐ 보통 | ⭐⭐⭐ 빠름 | ⭐⭐ 보통 |
| **의미 기반 검색** | ✅ 최적 | ❌ 부적합 | ⚠️ 조건부 | ❌ 부적합 |
| **OpenAI 호환** | ✅ 완벽 | ❌ 부적합 | ⚠️ 가능 | ❌ 부적합 |

## 당신의 경우: **Cosine 선택 권장** ✅

### 사용 사례
- 동아리 소개, 회칙, 사업계획, FAQ 문서
- OpenAI Embeddings 사용
- RAG 시스템 구축
- 의미 기반 검색

### Cosine을 선택해야 하는 이유
1. ✅ **텍스트 임베딩에 최적**: OpenAI Embeddings는 텍스트를 벡터로 변환
2. ✅ **의미 기반 검색**: "동아리 가입 방법" 같은 질문에 적합
3. ✅ **벡터 크기 무시**: 문서 길이와 관계없이 의미만 비교
4. ✅ **OpenAI 권장**: OpenAI는 Cosine을 기본으로 사용
5. ✅ **RAG 시스템 표준**: 대부분의 RAG 시스템이 Cosine 사용

### 다른 옵션을 선택하면?

**Euclid 선택 시:**
- ❌ 텍스트 임베딩에 부적합
- ❌ 벡터 크기에 민감하여 부정확한 결과
- ❌ 고차원 벡터에서 성능 저하

**Dot 선택 시:**
- ⚠️ 정규화된 벡터에서만 Cosine과 유사
- ⚠️ OpenAI Embeddings는 정규화되지 않을 수 있음
- ⚠️ 결과가 일관되지 않을 수 있음

**Manhattan 선택 시:**
- ❌ 텍스트 임베딩에 부적합
- ❌ 의미 기반 검색에 적합하지 않음

## 실제 예시

### Cosine 사용 시
```
질문: "동아리 가입 방법은?"
→ 의미가 비슷한 문서를 찾음
→ "회칙" 문서에서 가입 절차 부분 검색
→ 정확한 결과 ✅
```

### Euclid 사용 시
```
질문: "동아리 가입 방법은?"
→ 벡터 크기에 민감
→ 문서 길이가 다르면 부정확한 결과
→ 부정확한 결과 ❌
```

## OpenAI Embeddings와의 호환성

### text-embedding-3-small / text-embedding-3-large
- **권장 거리 측정**: **Cosine** ✅
- OpenAI 공식 문서에서 Cosine 사용 권장
- 벡터가 정규화되어 있지 않을 수 있음
- Cosine이 의미 기반 검색에 최적

### 다른 모델 사용 시
- 모델 문서를 확인하여 권장 거리 측정 방법 확인
- 대부분의 텍스트 임베딩 모델: Cosine 권장
- 일부 모델: Dot 권장 (정규화된 벡터인 경우)

## 요약

**당신의 경우:**
- ✅ **Cosine 선택**
- ✅ Collection 이름: `possible`
- ✅ Vector Size: `1536` (text-embedding-3-small)
- ✅ Distance: `Cosine`
- ✅ Use Case: `Global Search`
- ✅ Search Config: `Simple Single embedding`

**이유:**
- 텍스트 임베딩에 최적
- OpenAI Embeddings와 완벽 호환
- 의미 기반 검색에 적합
- RAG 시스템 표준

**다른 옵션 사용 시기:**
- **Euclid**: 이미지 임베딩, 좌표 데이터
- **Dot**: 정규화된 벡터, 특정 모델 요구사항
- **Manhattan**: 격자형 데이터, 이상 탐지

